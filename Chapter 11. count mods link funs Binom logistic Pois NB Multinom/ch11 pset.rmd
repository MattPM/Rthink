---
title: 'Ch 11 p set'
output: github_document
---

```{r, show = FALSE}
knitr::opts_chunk$set(
  #tidy = TRUE,
  #tidy.opts = list(width.cutoff = 95),
  message = FALSE,
  warning = TRUE, 
  eval = TRUE
  # root.dir = here()
)

```

```{r}
suppressMessages(library(rethinking))
```


11E1 - log odds of pr = 0.35 
```{r}
log(0.35  / (1- 0.35))
```

11E2 - log odds of event = 3.2 what is p 

```{r}

inv_logit(3.2)

```

to get a feel for log odds vs p:  
at 50% p, log odds is 0 at 0.1 its around -2 and at 0.9 its around 2. 
```{r, fig.width=3, fig.height=3}
pvec = seq(0, 1, by = 0.1)
plot(pvec, log(pvec / (1-pvec)))
```


11E3 logistic regression beta = 1.7 what does it say about proportional change in odds of the event?  

logistic regression coefs are in units of log odds, so 1.7 is log odds. The odds is the exponentiated coefficient (transforms to the outcome scale)

```{r}
exp(1.7)
```

11E4  
Poisson regression requires an offset because the totla counts per class (exposure) can be different, i.e. sampling one hospital for events for a year and another for 2 years. Or in scRNAseq the rate parameter for a gene tells you something but to conrast, the total genes per cell (log UMI) needs to be accounted for. 

11M1  
the likelihood is the probability of the data given the model so in the case of aggregated binomial globe toss, 3 water one land, that is 3 W in 4 trials, by embedding this into the binomial probability distribution we are aggregating the the data, the multiplicity term wiht n choose k * 1-k is multiplying the number of ways to observe, ie.  W L W W | W W W L | W W L W etc. we then plug in the probability. For individual counts, we calculate p * (1- p) for each separately. Basically p is independent of the likeihood function. 

11M2  

Poisson regression coefficient 1.7:  

y[i] = Poisson(lambda[i])   
log(lambda[i]) = a + Bx[i]  

the a + bX term is equal to log(lambda), the change in the outcome is:  
```{r}
exp(1.7)
```

5.47 units for every 1 unit change of the predictor. *note, in looking up the correct answer to this, there was a slightly more nuanced answerusing ratio of means exp( a + Bx + 1) / exp(a + Bx); the top part of the fraction is the 1 unit of change in predictor, solving you get exp(B), as i calculated above. but important to note that the interpretation of this is the proportional change in the expected count very similar to proportional change in log odds from logistic regression*  

11M3 explain why logit link appropriate for binomial GLM.  

basically because binomial is mapping the linar model output which is 0 , inf onto 2 possible outcomes, yes, no, heads, tails, 1, 0 etc. The odds makes sense to use because we can write probability functions in terms of one outcome like heads then the odds (logit) captures p ( 1-p ).  

11M4 explain why log link appropriate for Poisson.  


the log link constrains predictions from the linear model onto a space that will not predict negative counts. When we get a prediction from the linear model:   

log(lambda) = a + Bx  

then lambda = exp(a + Bx)  
exp is raising e to the power of the linear model, so say a+ Bx evaluated to 5, the log link will make lambda at i =   
```{r}
2.71^-5
```
this is the exponential function:  
```{r}
exp(-5)
```


*It is conventional to use a logit link for a binomial GLM because we need to map the continuous linear model value to a probability parameter that is bounded between zero and one.*  

*It is conventional to use a log link for a Poisson GLM because we need to map the continuous linear model value to a mean that must be positive.*  

11M5 could it make sense to use a logit link with a poisson GLM?  
using a logit link makes the outcome bounded between 0 and 1.  
basically if you want to put a upper bound on the estimates. see manual ed 1 p73. One could potentially do this -- a cell does have an upper bound as to what the total counts could be, so we would expect the counts of individual genes to be some fraction of that total; we'd have to define this for eahc cell type and its more a function of the technology used.  


11M8 Kline data without hawaii interaction model  

likelihood for interaction model with a category and continuous var:  
y = a[group] + B[group] * predictor  

embed that in the glm using the link function on outcome  
log( y ) = ...  

```{r, results = 'hide'}
data("Kline")
d = Kline
d = d[!d$culture == 'Hawaii', ]
d$pop = log(d$population)


# fit frequentist binomial glm with log link
f1 = total_tools ~ 0 + pop + contact + pop*contact
m1 = glm(formula = f1, family = poisson(link = 'log'),data = d)

# fit mcmc binomial model 
f1.1 = alist(
  # estimand
  total_tools ~ dpois(lambda), 
  # likelihood
  log(lambda) <- a[cid] + B[cid]*pop, 
  # priors 
  a[cid] ~ dnorm(3, 0.3), 
  B[cid] ~ dnorm(0, 0.1)
)

# specify data 
dat = list(
  total_tools = d$total_tools, 
  pop = d$pop, 
  cid = factor(d$contact, levels = c('low', 'high'))
)

# fit model 
m1.1 = ulam(flist = f1.1, data = dat,cores = 4)

```


ok making up my own problem here want ot compare these outputs to emmeans functions. 






